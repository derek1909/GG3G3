{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad546cd7",
   "metadata": {},
   "source": [
    "### Project reports\n",
    "  - Broken down by _Tasks_ (see below), any notes you wish to make in how you or your group structured and carried out the tasks, and most importantly your __results__ in the form of completely labelled graphs, and __accompanying conclusions__ you draw from your results. \n",
    "  - Interim report about 4-6 pages(excluding appendices such as attached code, but _including_ figures).\n",
    "  - __All code__ that you used during to project must be attached as an appendix to your reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa7c4a2-98f7-4f6d-8841-b74dc713750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from models2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d9133-5bd6-4f34-a680-0268aecef4d6",
   "metadata": {},
   "source": [
    "# Week 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df778a9b-3b9c-4330-b5fa-53a9945c2051",
   "metadata": {},
   "source": [
    "### Task 1.1\n",
    "\n",
    "Study the code in `models.py`, specifically the implementations of the two models in the `StepModel` and `RampModel` classes. <br>\n",
    "The main part to study (and relate to the mathematical discussion above) is their `simulate` method/function. You create <br>\n",
    "an object instance of each model by providing the model parameters (both \"fit\" and \"fixed\" parameters, as named above)<br>\n",
    "to the class constructors: e.g. `ramp = RampModel(beta=...)`. <br>\n",
    "(Ignore the other input arguments in the class constructor `__init__` for now, and leave them at their default values.)<br>\n",
    "Once a model object is created you can use its `simulate` method to get an array of spike trains over multiple trials. <br>\n",
    "(For usage see the docstring (or run help via `ramp.simulate?`.) `simulate` will also return the generated latent variables, <br>\n",
    "and, optionally, the firing rates in different trials. \n",
    "\n",
    "**Visualise the simulated spike trains by writing code to make so-called \"spike raster\" plots.** See the bottom row of Figure 5<br>\n",
    "above for example spike raster: different rows represent the spike trains in different trials, and spikes are shown by dots. <br>\n",
    "(you can put a dot for every nonzero $n_t$, even if the nonzero value is more than 1; this is unlikely if you keep `Rh` below<br>\n",
    "50 Hz and use a `T` of at least 100 (recommended). At this stage it should not be time-consuming to use higher `T`'s as well,<br>\n",
    "e.g. `T = 1000` (corresponding to 1 millisecond time-steps). If you are simulating hundreds of trials, you don't want to include<br>\n",
    "all of them in the raster. Use your common sense to decide how many trials to include in the raster; this a visualisation tool used to get<br>\n",
    "an idea of how spike trains behave qualitatively by seeing a good number of example. \n",
    "\n",
    "**Vary the parameters of each model and generate spike rasters in different regions of the parameter space, trying to find<br>\n",
    "qualitatively different behavior.** The default values of the parameters give you a first guess or the right order of magnitude for the <br>\n",
    "different parameters. (For `m` and `r` of the step model, note that they should scale with the `T` you will be using for the simulation;<br>\n",
    "in particular, for more interesting/relevant results, you would want to set `m` at or near `T / 2` so that the steps happen on average in the middle of the trial.)\n",
    "\n",
    "**What systematic patterns can you detect?**\n",
    "\n",
    "**Write code to also mark the jump times in different trials over the spike trains in the raster. <br>\n",
    "Also make histograms of jump times. What is the effect of the `r` parameter on the behaiour of the stepping model?**<br>\n",
    "\n",
    "**Similarly make plots of the trajectories of $x_t$ or $r_t$ (of the ramp model) in several trials, in a single plot.<br>\n",
    "You can extract the time when $x_t$ of the ramping model hits its upper bound of 1 (equivalently $r_t$ reaches $R_h$), and histogram that as well.<br>**\n",
    "**How do `beta` and `sigma` affect this histogram or the behaviour of the $x_t$ trajectories?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62e9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "T = 100\n",
    "times_ms = np.linspace(1e3/T,1e3,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e0e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "for beta in [0.4, 1, 3]:\n",
    "    for sigma, x0 in [[0,0.2], [0.2, 0.6], [0.2, 0.2], [0.5,0.2],[1.6,0.2]]:\n",
    "\n",
    "        ramp = RampModel(beta, sigma, x0, Rh=50)\n",
    "        ramp_arr = ramp.simulate(Ntrials=N, get_rate=True, T = T)\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(2)\n",
    "        fig.suptitle(f\"Spike Raster Plot for Ramp Model\\n beta={beta}, sigma={sigma}, x0={x0}, N={N}, T{T}\")\n",
    "\n",
    "        for i in range(len(ramp_arr[2])):\n",
    "            ax1.plot(times_ms, ramp_arr[2][i], linewidth = 2)\n",
    "        ax1.set_ylabel(\"spike rate (sp/s)\")\n",
    "        ax1.set_ylim(0, 60)\n",
    "\n",
    "        # record time of spikes in milliseconds\n",
    "        spike_trains_timestamp = []\n",
    "        for spike_train in ramp_arr[0]: # for each trail\n",
    "            timestamp = []\n",
    "            for i in range(len(spike_train)): # for each time point\n",
    "                #if spike_train[i]!=0:          # if an spike event occurs at this time stamp\n",
    "                for j in range(spike_train[i]): # This change is to handle the case where there are multiple spikes in a time stamp\n",
    "                    timestamp.append(i*1e3/T)\n",
    "            spike_trains_timestamp.append(timestamp)\n",
    "\n",
    "        colors1 = ['C{}'.format(i) for i in range(len(ramp_arr[0]))] #set different color for each set of neural data\n",
    "        ax2.eventplot(spike_trains_timestamp, colors=colors1, linelengths=0.4, linewidths=2)\n",
    "        ax2.yaxis.set_tick_params(labelleft=False)\n",
    "        ax2.set_xlabel(\"time from motion onset (ms)\")\n",
    "        ax2.set_ylabel(\"spike trains\")\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "        filename = f\"results/1.1/raster_ramp_b{beta}_s{sigma}_x0={x0}_N{N}_T{T}.png\"\n",
    "\n",
    "        # Save the plot\n",
    "        plt.savefig(filename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5601fd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "for m in [20, 50, 80]:\n",
    "    for r, x0 in [[1e-1, 0.2], [1e0, 0.2], [1e1, 0.6], [1e1, 0.2], [1e3,0.2],[1e10,0.2]]:\n",
    "        \n",
    "        step = StepModel(m, r, x0, Rh=50)\n",
    "        step_arr = step.simulate(Ntrials=N, get_rate=True, T = T)\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(2)\n",
    "        fig.suptitle(plt.hist)\n",
    "\n",
    "        for i in range(len(step_arr[2])):\n",
    "            ax1.plot(times_ms, step_arr[2][i])\n",
    "        ax1.set_ylabel(\"spike rate (sp/s)\")\n",
    "        ax1.set_ylim(0, 60)\n",
    "\n",
    "        # record time of spikes in milliseconds\n",
    "        spike_trains_timestamp = []\n",
    "        for spike_train in step_arr[0]: # for each trail\n",
    "            timestamp = []\n",
    "            for i in range(len(spike_train)):   # for each time point\n",
    "                #if spike_train[i]!=0:          # if an spike event occurs at this time stamp\n",
    "                for j in range(spike_train[i]): # This change is to handle the case where there are multiple spikes in a time stamp\n",
    "                    timestamp.append(i*1e3/T)\n",
    "\n",
    "            spike_trains_timestamp.append(timestamp)\n",
    "        colors1 = ['C{}'.format(i) for i in range(len(step_arr[0]))] #set different color for each set of neural data\n",
    "        ax2.eventplot(spike_trains_timestamp, colors=colors1, linelengths=0.4, linewidths=2)\n",
    "        ax2.yaxis.set_tick_params(labelleft=False)\n",
    "        ax2.set_xlabel(\"time from motion onset (ms)\")\n",
    "        ax2.set_ylabel(\"spike trains\")\n",
    "\n",
    "        fig.suptitle(f\"Spike Raster Plot for Step Model\\n m={m}, r={r}, x0={x0}, N={N}, T{T}\")\n",
    "        filename = f\"results/1.1/raster_step_m{m}_r{r}_x0={x0}_N{N}_T{T}.png\"\n",
    "\n",
    "        plt.savefig(filename,bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import geom\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "for r in [1e-2, 0.7, 1e0, 3, 3* 1e1, 1e3]:\n",
    "    step = StepModel(m=50,r=r, x0=0.2, Rh=50);\n",
    "    T = 100\n",
    "    N = 10000\n",
    "    jump_time = step.simulate(Ntrials=N, get_rate=False, T = T)[1]\n",
    "    jump_time = jump_time*1e3/T # ms\n",
    "    plt.hist(jump_time, 50, [0,1000])\n",
    "    \n",
    "    if r == 1:\n",
    "        p = 1/51  # probability of success\n",
    "        # Calculate binomial distribution\n",
    "        geometric_distribution = geom.pmf(times_ms/10, p) * 200 * N / T\n",
    "        plt.ylim(0,400)\n",
    "        # Create the plot\n",
    "        plt.plot(times_ms, geometric_distribution, label=\"geometric distribution with p=1/51\", linewidth=4)\n",
    "        plt.legend()\n",
    "    if r >= 1e1:\n",
    "        gaussian_distribution = norm.pdf(times_ms/10, 50, 50**0.5) * 200 * N / T\n",
    "        # Create the plot\n",
    "        plt.plot(times_ms, gaussian_distribution, label=\"gaussian distribution with mean=5=50, var=m=50\", linewidth=4)\n",
    "        plt.legend()\n",
    "\n",
    "    plt.xlabel(\"time from motion onset (ms)\")\n",
    "    plt.ylabel(\"# jumps\")\n",
    "    plt.title(f\"jump time of STEP model, r={r}, N=1000, bin size = 20\")\n",
    "    plt.xlim(0,1000)\n",
    "    filename = f\"results/1.1/jumptime_step_r{r}.png\"\n",
    "    plt.savefig(filename,bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfc70b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 2\n",
    "from scipy.stats import skewnorm\n",
    "from scipy.stats import norm\n",
    "\n",
    "for sigma in [0.01, 0.1, 0.2, 1, 5, 1e2, 1e4]:\n",
    "\n",
    "    ramp = RampModel(beta=beta, sigma=sigma, x0=.2, Rh=50)\n",
    "    T = 100\n",
    "    N = 10000\n",
    "    X = ramp.simulate(Ntrials=N, get_rate=False, T = T)[1]\n",
    "    max_time = []\n",
    "    for x in X:\n",
    "        for i in range(T):\n",
    "            if x[i] == 1.0:\n",
    "                max_time.append(i*1e3/T)\n",
    "                break\n",
    "    hist , _, _ = plt.hist(max_time, 50, [0,1000])\n",
    "\n",
    "    if sigma <= 1:\n",
    "\n",
    "        tau = 0.8/beta\n",
    "        gaussian_distribution = norm.pdf((0.8-beta*(times_ms/1000)), 0, sigma* (times_ms/1000)**0.5)\n",
    "        normalised = gaussian_distribution / np.sum(gaussian_distribution) * 200 * N / T\n",
    "        # Create the plot\n",
    "        plt.plot(times_ms, normalised, label=\"Derived distribution for SMALL sigma\", linewidth=3)\n",
    "        plt.legend()\n",
    "        plt.ylim(0,np.max(hist) * 1.2)\n",
    "\n",
    "        \n",
    "        \n",
    "    if sigma >= 5:\n",
    "\n",
    "        tau = 0.8/beta\n",
    "        gaussian_distribution = norm.pdf((1-0.2)/sigma**2/(times_ms/10), 0, 1) * (1-0.8)/(sigma**2 * (times_ms/10)**2)\n",
    "        normalised = gaussian_distribution / np.sum(gaussian_distribution) * 200 * N / T\n",
    "\n",
    "        # Create the plot\n",
    "        plt.plot(times_ms, normalised, label=\"Derived distribution for LARGE sigma\", linewidth=3)\n",
    "        plt.legend()\n",
    "        plt.ylim(0,6000)\n",
    "\n",
    "\n",
    "    plt.xlabel(\"time from motion onset (ms)\")\n",
    "    plt.ylabel(\"# jumps\")\n",
    "    plt.title(f\"jump time of RAMP model, sigma={sigma}, beta={beta}, N=1000, bin size = 20\")\n",
    "    plt.xlim(0,1000)\n",
    "    filename = f\"results/1.1/jumptime_RAMP_s{sigma}_beta{beta}.png\"\n",
    "    plt.savefig(filename,bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20ba518-9a6b-4eac-87f1-b3d2c7477733",
   "metadata": {},
   "source": [
    "### Task 1.2\n",
    "\n",
    "PSTH is an important data analysis tool used in neuroscience.<br> \n",
    "This  is a statistical estimate of the trial-averaged firing rate as a function of time, based on recordings of spike trains in<br>\n",
    "multiple experimental trials. It is obtained by binning/histogramming spikes (e.g. using `np.histogram`) in different time bins<br>\n",
    "and averaging the resulting spike counts over many trials (you can also divide by `dt` to turn into rate in units of Hz).<br>\n",
    "\n",
    "**Write code to construct and plot PSTH's in different regions of each model's parameter space.** Note how the PSTH <br>\n",
    "fluctuates randomly from dataset to dataset. **It is better to do some sort of (temporal) smoothing in order to reduce these<br>**\n",
    "fluctuations and the jaggedness of the PSTH. You can use either a sliding window (e.g. a boxcar window/functin) averaging, or simply <br>\n",
    "use time bins that are larger than the oridinal time steps (e.g. 50 milliseconds -- or 5 timesteps if you are using a `dt` of 10 ms,<br> \n",
    "corresponding to `T = 100`). The smooth ramping firing rate curves in Figure 4 of the [Background](https://github.com/ahmadianlab/gg3_nda/blob/main/Background.ipynb)\n",
    "are examples of smoothed PSTH's.\n",
    "\n",
    "Even with the smoothing there will be fluctuations in the PSTH from dataset to dataset. **How does the strength of these fluctuations <br>depend on (or scale with) the number of trials (in each dataset)? Try to be quantitative about this, e.g. by using informed plots. <br>**\n",
    "For the rest of this task use a high number of trials (e.g. 5000) to minimise these fluctuations. (But note <br>\n",
    "that in real experiments the number of trials rarely exceeds a few hundred -- for for later tasks we will bring the number down.)\n",
    "\n",
    "\n",
    "Finally, **try to find parameter regimes that make the PSTH of the stepping model very close to that of the ramp model. (First make sure<br>\n",
    "the ramp model's PSTH look qualitatively like the classic ramping PSTH's in LIP experiments.) In which parameter regions<br>\n",
    "does this fail drastically, and in which regimes are the two PSTH's nearly indistinguishable?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e96e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_list = [0.1, 0.5, 1]\n",
    "sigma_list = [0.02, 0.2, 2]\n",
    "from models import *\n",
    "from models2 import *\n",
    "for b in beta_list:\n",
    "    for s in sigma_list:\n",
    "        \n",
    "        ramp = RampModel(beta=b, sigma=s, x0=.2, Rh=50)\n",
    "        T = 100\n",
    "        N = 5000\n",
    "        ramp_arr = ramp.simulate(Ntrials=N, get_rate=False, T = T)\n",
    "        bin_size = 20\n",
    "        bin_edges = np.arange(0, 1e3+bin_size, bin_size)\n",
    "\n",
    "        ## this method considers the multi-spike issue ##\n",
    "        averaged_psth, gaussian_smoothed_psth, _, _ = generate_psth(spike_trains=ramp_arr[0], bin_size=bin_size, bin_size_2=50, plot=False);\n",
    "\n",
    "        \n",
    "        # record time of spikes in milliseconds\n",
    "        spike_trains_timestamp = []\n",
    "        for spike_train in ramp_arr[0]:\n",
    "            timestamp = []\n",
    "            for i in range(len(spike_train)):\n",
    "                ## this method ignores the multi-spike issue ##\n",
    "                if spike_train[i]!=0: \n",
    "                    timestamp.append(i*1e3/T)\n",
    "            spike_trains_timestamp.append(timestamp)\n",
    "\n",
    "        # Calculate the PSTH\n",
    "        psth_ignore, _ = np.histogram(np.concatenate(spike_trains_timestamp), bins=bin_edges)\n",
    "\n",
    "        from scipy.ndimage import gaussian_filter\n",
    "        sigma = 1.5 # Standard deviation of the Gaussian filter\n",
    "        smoothed_psth_ignore = gaussian_filter((psth_ignore / bin_size * 1e3) / N, sigma)\n",
    "        \n",
    "        \n",
    "        # Plot the PSTH\n",
    "        plt.plot(bin_edges[:-1], averaged_psth,  label='Original', linewidth = 2)\n",
    "        plt.plot(bin_edges[:-1], gaussian_smoothed_psth,  label='Smoothed', linewidth = 2)\n",
    "        plt.plot(bin_edges[:-1], smoothed_psth_ignore,  label='Multi-spikes ignored', linewidth = 1.5)\n",
    "\n",
    "        plt.ylabel(\"spike rate (sp/s)\")\n",
    "        plt.xlabel(\"time from motion onset (ms)\")\n",
    "        plt.ylim(0,45)\n",
    "        plt.xlim(0,1000)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.title(f\"PSTH for RAMP model, sigma={s}, beta={b}, bin size = 20\")\n",
    "        filename = f\"results/1.2/PSTH_RAMP_s{s}_beta{b}.png\"\n",
    "        plt.savefig(filename,bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6c8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_list = [10,50,90]\n",
    "r_list = [1, 10, 100]\n",
    "for m in m_list:\n",
    "    for r in r_list:\n",
    "        step = StepModel(m=m, r=r, x0=0.2, Rh=50)\n",
    "        T = 100\n",
    "        N = 5000\n",
    "        step_arr = step.simulate(Ntrials=N, get_rate=False, T = T)\n",
    "        bin_size=20\n",
    "        bin_edges = np.arange(0, 1e3+bin_size, bin_size)\n",
    "        \n",
    "        ## this method considers the multi-spike issue ##\n",
    "        averaged_psth, gaussian_smoothed_psth, _, _ = generate_psth(spike_trains=step_arr[0], bin_size=bin_size, bin_size_2=50, plot=False);\n",
    "\n",
    "        # record time of spikes in milliseconds\n",
    "        spike_trains_timestamp = []\n",
    "        for spike_train in step_arr[0]:\n",
    "            timestamp = []\n",
    "            for i in range(len(spike_train)):\n",
    "                ## this method ignores the multi-spike issue ##\n",
    "                if spike_train[i]!=0: \n",
    "                    timestamp.append(i*1e3/T)\n",
    "            spike_trains_timestamp.append(timestamp)\n",
    "\n",
    "        # Calculate the PSTH\n",
    "        psth_ignore, _ = np.histogram(np.concatenate(spike_trains_timestamp), bins=bin_edges)\n",
    "\n",
    "        from scipy.ndimage import gaussian_filter\n",
    "        sigma = 1.5 # Standard deviation of the Gaussian filter\n",
    "        smoothed_psth_ignore = gaussian_filter((psth_ignore / bin_size * 1e3) / N, sigma)\n",
    "        \n",
    "        \n",
    "        # Plot the PSTH\n",
    "        plt.plot(bin_edges[:-1], averaged_psth,  label='Original', linewidth = 2)\n",
    "        plt.plot(bin_edges[:-1], gaussian_smoothed_psth,  label='Smoothed', linewidth = 2)\n",
    "        plt.plot(bin_edges[:-1], smoothed_psth_ignore,  label='Multi-spikes ignored', linewidth = 1.5)\n",
    "\n",
    "        plt.ylabel(\"spike rate (sp/s)\")\n",
    "        plt.xlabel(\"time from motion onset (ms)\")\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.ylim(0,55)  \n",
    "        plt.title(f\"PSTH for STEP model, r={r}, m={m}, bin size = 20\")\n",
    "        plt.xlim(0,1000)\n",
    "        filename = f\"results/1.2/PSTH_STEP_r{r}_m{m}.png\"\n",
    "        plt.savefig(filename,bbox_inches='tight')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892cf996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the strength of fluctuations depend on the number of trials?\n",
    "b=0.5\n",
    "s=0.2\n",
    "\n",
    "m=50\n",
    "r=0.2\n",
    "ramp = RampModel(beta=0.5, sigma=0.2, x0=.2, Rh=50)\n",
    "step = StepModel(m=m, r=r, x0=0.2, Rh=50)\n",
    "T = 100\n",
    "\n",
    "bin_size=20\n",
    "bin_edges = np.arange(0, 1e3+bin_size, bin_size)\n",
    "bin_size_2=50\n",
    "bin_edges_2 = np.arange(0, 1e3+bin_size_2, bin_size_2)    \n",
    "\n",
    "number_of_trails = [10, 100, 1000, 10000]\n",
    "number_of_dataset = 10\n",
    "psth_s = np.empty((number_of_dataset,int(1000/bin_size) ))\n",
    "\n",
    "for n in number_of_trails:\n",
    "    for ii in range(number_of_dataset):\n",
    "        arr = ramp.simulate(Ntrials=n, get_rate=False, T = T)\n",
    "\n",
    "        averaged_psth, gaussian_smoothed_psth, var_s, _ = generate_psth(spike_trains=arr[0], bin_size=bin_size, bin_size_2=bin_size_2, plot=False);\n",
    "        psth_s[ii] = gaussian_smoothed_psth\n",
    "\n",
    "    var = np.var(psth_s, axis=0)\n",
    "\n",
    "    plt.plot(bin_edges[:-1], var,  label=f\"# trials = {n}\", linewidth = 2)\n",
    "\n",
    "plt.ylabel(\"variance\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"time from motion onset (ms)\")\n",
    "plt.legend()\n",
    "plt.title(f\"PSTH fluctuations vs the number of trials (ramp model)\")\n",
    "filename = f\"results/1.2/fluctuations_PSTH_ramp.png\"\n",
    "plt.savefig(filename,bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dab3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantifying the fluctuation with average variance\n",
    "\n",
    "# Gives average variance over 10 datasets of Ramp Model with beta = 0.5 and sigma = 0.2 and given number of trials\n",
    "def get_average_variance(N):\n",
    "    ramp = RampModel(beta=0.5, sigma=0.2, x0=.2, Rh=50)\n",
    "    T = 100\n",
    "    # N = 50\n",
    "    number_of_dataset = 10\n",
    "    psth_list = []\n",
    "    for _ in range(number_of_dataset):\n",
    "        ramp_arr = ramp.simulate(Ntrials=N, get_rate=False, T = T)\n",
    "\n",
    "        # record time of spikes in milliseconds\n",
    "        spike_trains_timestamp = []\n",
    "        for spike_train in ramp_arr[0]:\n",
    "            timestamp = []\n",
    "            for i in range(len(spike_train)):\n",
    "                if spike_train[i]!=0:\n",
    "                    timestamp.append(i*1e3/T)\n",
    "            spike_trains_timestamp.append(timestamp)\n",
    "\n",
    "        # Calculate the PSTH\n",
    "        bin_size = 20  # Choose an appropriate bin size for the PSTH (in milliseconds)\n",
    "        bin_edges = np.arange(0, 1e3+bin_size, bin_size)\n",
    "        psth, _ = np.histogram(np.concatenate(spike_trains_timestamp), bins=bin_edges)\n",
    "\n",
    "        averaged_psth = (psth / bin_size * 1e3) / N # spikes per sec per trail\n",
    "\n",
    "        from scipy.ndimage import gaussian_filter\n",
    "        sigma = 1.5 # Standard deviation of the Gaussian filter\n",
    "\n",
    "        # Apply Gaussian smoothing\n",
    "        gaussian_smoothed_psth = gaussian_filter(averaged_psth, sigma)\n",
    "\n",
    "        psth_list.append(gaussian_smoothed_psth)\n",
    "\n",
    "    variance = []\n",
    "    for i in range(len(psth_list[0])):\n",
    "        data = []\n",
    "        for psth in psth_list:\n",
    "            data.append(psth[i])\n",
    "        variance.append(np.var(data))\n",
    "    average_variance = np.average(variance)\n",
    "    return average_variance\n",
    "n_trials = np.linspace(50,5000,50)\n",
    "avg_var = [get_average_variance(int(n)) for n in n_trials]\n",
    "plt.plot(n_trials, avg_var, linewidth = 2)\n",
    "plt.xlabel(\"Number of trials\")\n",
    "plt.ylabel(\"Average variance (log-scale)\")\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.title(f\"PSTH fluctuations vs the number of trials\")\n",
    "filename = f\"results/1.2/fluctuations_PSTH.png\"\n",
    "plt.savefig(filename,bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e5556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "## Indistinguishable regime 1\n",
    "\n",
    "T = 100\n",
    "N = 4000\n",
    "times_ms = np.linspace(1e3/T,1e3,T)\n",
    "\n",
    "b = 1\n",
    "m = 50\n",
    "r = 0.001\n",
    "s = 1e4\n",
    "x_r = 0.3\n",
    "x_s = 0.15\n",
    "\n",
    "sigma = 1.5\n",
    "\n",
    "fig, ax2 = plt.subplots() # ax2 is for jump time hist\n",
    "ax1 = ax2.twinx() # ax2 is for PSTH\n",
    "\n",
    "bin_size=20\n",
    "bin_edges = np.arange(0, 1e3+bin_size, bin_size)\n",
    "bin_size_2=50\n",
    "bin_edges_2 = np.arange(0, 1e3+bin_size_2, bin_size_2)   \n",
    "\n",
    "#step model\n",
    "step = StepModel(m=m, r=r, x0=x_s, Rh=50)\n",
    "step_arr = step.simulate(Ntrials=N, get_rate=False, T = T)\n",
    "averaged_psth, gaussian_smoothed_psth, _, _ = generate_psth(spike_trains=step_arr[0], bin_size=bin_size, bin_size_2=50, plot=False);\n",
    "grad_step = np.gradient(gaussian_smoothed_psth, 1/50)\n",
    "ax1.plot(bin_edges[:-1], gaussian_smoothed_psth,  label='step model psth', linewidth=2, color='#1f77b4')# Light Blue\n",
    "\n",
    "\n",
    "#ramp model\n",
    "ramp = RampModel(beta=b, sigma=s, x0=x_r, Rh=50)\n",
    "ramp_arr = ramp.simulate(Ntrials=N, get_rate=False, T = T)\n",
    "averaged_psth, gaussian_smoothed_psth, _, _ = generate_psth(spike_trains=ramp_arr[0], bin_size=bin_size, bin_size_2=50, plot=False);\n",
    "grad_ramp = np.gradient(gaussian_smoothed_psth, 1/50)\n",
    "ax1.plot(bin_edges[:-1], gaussian_smoothed_psth,  label='ramp model psth',linewidth=2, color='#ff7f0e')  # Light Orange\n",
    "\n",
    "\n",
    "\n",
    "#step jump time distribution\n",
    "jump_time = step_arr[1]\n",
    "jump_time = jump_time*1e3/T # ms\n",
    "ax2.hist(jump_time, 50, [0,1000], label=\"step model jump times\", color='#2ca02c')  # Dark Blue\n",
    "\n",
    "    \n",
    "#ramp jump time distribution\n",
    "X = ramp_arr[1]\n",
    "max_time = []\n",
    "for x in X:\n",
    "    for i in range(T):\n",
    "        if x[i] == 1.0:\n",
    "            max_time.append(i*1e3/T)\n",
    "            break\n",
    "hist , _, _ = ax2.hist(max_time, 50, [0,1000], label=\"ramp model jump times\", color='#d62728')  # Dark Orange\n",
    "\n",
    "ax2.set_ylabel(\"# jumps\")\n",
    "\n",
    "\n",
    "ax1.set_ylabel(\"spike rate (sp/s)\")\n",
    "ax1.set_xlabel(\"time from motion onset (ms)\")\n",
    "ax1.set_ylim(0,55)\n",
    "\n",
    "ax1.set_title(f\"Regime 1\\n r={r}, m={m}, Xs={x_s}, s={s}, beta={b}, Xr={x_r}\")\n",
    "filename = f\"results/1.2/similar_step_ramp.png\"\n",
    "ax2.set_xlabel(\"time from motion onset (ms)\")\n",
    "ax2.set_xlim(0,1000)\n",
    "fig.legend(loc=(0.55, 0.14))\n",
    "\n",
    "\n",
    "filename = f\"results/1.2/Similar models, regime, r={r}, m={m}, s={s}, beta={b}.png\"\n",
    "plt.savefig(filename,bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eb269e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da36db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indistinguishable regime 2 (counter)\n",
    "\n",
    "T = 100\n",
    "N = 4000\n",
    "times_ms = np.linspace(1e3/T,1e3,T)\n",
    "\n",
    "b = 1\n",
    "m = 50\n",
    "r = 1e4\n",
    "s = 0.01\n",
    "x_r = 0.3\n",
    "x_s = 0.15\n",
    "m=(1-x_r)/(b) * T\n",
    "print(m)\n",
    "\n",
    "sigma = 1.5 #gaussian filter\n",
    "\n",
    "fig, ax2 = plt.subplots() # ax2 is for jump time hist\n",
    "ax1 = ax2.twinx() # ax2 is for PSTH\n",
    "\n",
    "bin_size=20\n",
    "bin_edges = np.arange(0, 1e3+bin_size, bin_size)\n",
    "bin_size_2=50\n",
    "bin_edges_2 = np.arange(0, 1e3+bin_size_2, bin_size_2)   \n",
    "\n",
    "#step model\n",
    "step = StepModel(m=m, r=r, x0=x_s, Rh=50)\n",
    "step_arr = step.simulate(Ntrials=N, get_rate=False, T = T)\n",
    "averaged_psth, gaussian_smoothed_psth, _, _ = generate_psth(spike_trains=step_arr[0], bin_size=bin_size, bin_size_2=50, plot=False);\n",
    "grad_step = np.gradient(gaussian_smoothed_psth, 1/50)\n",
    "ax1.plot(bin_edges[:-1], gaussian_smoothed_psth,  label='step model psth', linewidth=2, color='#1f77b4')# Light Blue\n",
    "\n",
    "\n",
    "#ramp model\n",
    "ramp = RampModel(beta=b, sigma=s, x0=x_r, Rh=50)\n",
    "ramp_arr = ramp.simulate(Ntrials=N, get_rate=False, T = T)\n",
    "averaged_psth, gaussian_smoothed_psth, _, _ = generate_psth(spike_trains=ramp_arr[0], bin_size=bin_size, bin_size_2=50, plot=False);\n",
    "grad_ramp = np.gradient(gaussian_smoothed_psth, 1/50)\n",
    "ax1.plot(bin_edges[:-1], gaussian_smoothed_psth,  label='ramp model psth',linewidth=2, color='#ff7f0e')  # Light Orange\n",
    "\n",
    "\n",
    "\n",
    "#step jump time distribution\n",
    "jump_time = step_arr[1]\n",
    "jump_time = jump_time*1e3/T # ms\n",
    "ax2.hist(jump_time, 50, [0,1000], label=\"step model jump times\", color='#2ca02c')  # Dark Blue\n",
    "\n",
    "    \n",
    "#ramp jump time distribution\n",
    "X = ramp_arr[1]\n",
    "max_time = []\n",
    "for x in X:\n",
    "    for i in range(T):\n",
    "        if x[i] == 1.0:\n",
    "            max_time.append(i*1e3/T)\n",
    "            break\n",
    "hist , _, _ = ax2.hist(max_time, 50, [0,1000], label=\"ramp model jump times\", color='#d62728')  # Dark Orange\n",
    "\n",
    "ax2.set_ylabel(\"# jumps\")\n",
    "\n",
    "\n",
    "ax1.set_ylabel(\"spike rate (sp/s)\")\n",
    "ax1.set_xlabel(\"time from motion onset (ms)\")\n",
    "ax1.set_ylim(0,55)\n",
    "\n",
    "ax1.set_title(f\"Regime 2 (counter-example)\\n r={r}, m={m}, s={s}, X_s={x_s} beta={b}, Xr={x_r}\")\n",
    "filename = f\"results/1.2/similar_step_ramp.png\"\n",
    "ax2.set_xlabel(\"time from motion onset (ms)\")\n",
    "ax2.set_xlim(0,1000)\n",
    "fig.legend(loc=(0.15, 0.67))\n",
    "\n",
    "\n",
    "filename = f\"results/1.2/Similar models, regime 2, r={r}, m={m}, s={s}, beta={b}(regime 2)(beta not sufficiently large).png\"\n",
    "plt.savefig(filename,bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53872428",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indistinguishable regime 2\n",
    "\n",
    "T = 100\n",
    "N = 4000\n",
    "times_ms = np.linspace(1e3/T,1e3,T)\n",
    "\n",
    "b = 50\n",
    "m = 50\n",
    "r = 1e4\n",
    "s = 0.01\n",
    "x_r = 0.3\n",
    "x_s = 0.15\n",
    "m=(1-x_r)/(b) * T\n",
    "print(m)\n",
    "\n",
    "sigma = 1.5 #gaussian filter\n",
    "\n",
    "fig, ax2 = plt.subplots() # ax2 is for jump time hist\n",
    "ax1 = ax2.twinx() # ax2 is for PSTH\n",
    "\n",
    "bin_size=20\n",
    "bin_edges = np.arange(0, 1e3+bin_size, bin_size)\n",
    "bin_size_2=50\n",
    "bin_edges_2 = np.arange(0, 1e3+bin_size_2, bin_size_2)   \n",
    "\n",
    "#step model\n",
    "step = StepModel(m=m, r=r, x0=x_s, Rh=50)\n",
    "step_arr = step.simulate(Ntrials=N, get_rate=False, T = T)\n",
    "averaged_psth, gaussian_smoothed_psth, _, _ = generate_psth(spike_trains=step_arr[0], bin_size=bin_size, bin_size_2=50, plot=False);\n",
    "grad_step = np.gradient(gaussian_smoothed_psth, 1/50)\n",
    "ax1.plot(bin_edges[:-1], gaussian_smoothed_psth,  label='step model psth', linewidth=2, color='#1f77b4')# Light Blue\n",
    "\n",
    "\n",
    "#ramp model\n",
    "ramp = RampModel(beta=b, sigma=s, x0=x_r, Rh=50)\n",
    "ramp_arr = ramp.simulate(Ntrials=N, get_rate=False, T = T)\n",
    "averaged_psth, gaussian_smoothed_psth, _, _ = generate_psth(spike_trains=ramp_arr[0], bin_size=bin_size, bin_size_2=50, plot=False);\n",
    "grad_ramp = np.gradient(gaussian_smoothed_psth, 1/50)\n",
    "ax1.plot(bin_edges[:-1], gaussian_smoothed_psth,  label='ramp model psth',linewidth=2, color='#ff7f0e')  # Light Orange\n",
    "\n",
    "\n",
    "\n",
    "#step jump time distribution\n",
    "jump_time = step_arr[1]\n",
    "jump_time = jump_time*1e3/T # ms\n",
    "ax2.hist(jump_time, 50, [0,1000], label=\"step model jump times\", color='#2ca02c')  # Dark Blue\n",
    "\n",
    "    \n",
    "#ramp jump time distribution\n",
    "X = ramp_arr[1]\n",
    "max_time = []\n",
    "for x in X:\n",
    "    for i in range(T):\n",
    "        if x[i] == 1.0:\n",
    "            max_time.append(i*1e3/T)\n",
    "            break\n",
    "hist , _, _ = ax2.hist(max_time, 50, [0,1000], label=\"ramp model jump times\", color='#d62728')  # Dark Orange\n",
    "\n",
    "ax2.set_ylabel(\"# jumps\")\n",
    "\n",
    "\n",
    "ax1.set_ylabel(\"spike rate (sp/s)\")\n",
    "ax1.set_xlabel(\"time from motion onset (ms)\")\n",
    "ax1.set_ylim(0,55)\n",
    "\n",
    "ax1.set_title(f\"Regime 2 \\n r={r}, m={m}, s={s}, X_s={x_s} beta={b}, Xr={x_r}\")\n",
    "filename = f\"results/1.2/similar_step_ramp.png\"\n",
    "ax2.set_xlabel(\"time from motion onset (ms)\")\n",
    "ax2.set_xlim(0,1000)\n",
    "fig.legend(loc=(0.55, 0.14))\n",
    "\n",
    "\n",
    "filename = f\"results/1.2/Similar models, regime 2, r={r}, m={m}, s={s}, beta={b}(regime 2).png\"\n",
    "plt.savefig(filename,bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402dec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indistinguishable regime 3\n",
    "\n",
    "T = 100\n",
    "N = 4000\n",
    "times_ms = np.linspace(1e3/T,1e3,T)\n",
    "\n",
    "b = 1\n",
    "r = 2\n",
    "s = 1.1\n",
    "x_r = 0.3\n",
    "x_s = 0.15\n",
    "m=(1-x_r)/(2*b) * T\n",
    "print(m)\n",
    "\n",
    "sigma = 1.5 #gaussian filter\n",
    "\n",
    "fig, ax2 = plt.subplots() # ax2 is for jump time hist\n",
    "ax1 = ax2.twinx() # ax2 is for PSTH\n",
    "\n",
    "bin_size=20\n",
    "bin_edges = np.arange(0, 1e3+bin_size, bin_size)\n",
    "bin_size_2=50\n",
    "bin_edges_2 = np.arange(0, 1e3+bin_size_2, bin_size_2)   \n",
    "\n",
    "#step model\n",
    "step = StepModel(m=m, r=r, x0=x_s, Rh=50)\n",
    "step_arr = step.simulate(Ntrials=N, get_rate=False, T = T)\n",
    "averaged_psth, gaussian_smoothed_psth, _, _ = generate_psth(spike_trains=step_arr[0], bin_size=bin_size, bin_size_2=50, plot=False);\n",
    "grad_step = np.gradient(gaussian_smoothed_psth, 1/50)\n",
    "ax1.plot(bin_edges[:-1], gaussian_smoothed_psth,  label='step model psth', linewidth=2, color='#1f77b4')# Light Blue\n",
    "\n",
    "\n",
    "#ramp model\n",
    "ramp = RampModel(beta=b, sigma=s, x0=x_r, Rh=50)\n",
    "ramp_arr = ramp.simulate(Ntrials=N, get_rate=False, T = T)\n",
    "averaged_psth, gaussian_smoothed_psth, _, _ = generate_psth(spike_trains=ramp_arr[0], bin_size=bin_size, bin_size_2=50, plot=False);\n",
    "grad_ramp = np.gradient(gaussian_smoothed_psth, 1/50)\n",
    "ax1.plot(bin_edges[:-1], gaussian_smoothed_psth,  label='ramp model psth',linewidth=2, color='#ff7f0e')  # Light Orange\n",
    "\n",
    "\n",
    "\n",
    "#step jump time distribution\n",
    "jump_time = step_arr[1]\n",
    "jump_time = jump_time*1e3/T # ms\n",
    "ax2.hist(jump_time, 50, [0,1000], label=\"step model jump times\", color='#2ca02c')  # Dark Blue\n",
    "\n",
    "    \n",
    "#ramp jump time distribution\n",
    "X = ramp_arr[1]\n",
    "max_time = []\n",
    "for x in X:\n",
    "    for i in range(T):\n",
    "        if x[i] == 1.0:\n",
    "            max_time.append(i*1e3/T)\n",
    "            break\n",
    "hist , _, _ = ax2.hist(max_time, 50, [0,1000], label=\"ramp model jump times\", color='#d62728')  # Dark Orange\n",
    "\n",
    "ax2.set_ylabel(\"# jumps\")\n",
    "\n",
    "\n",
    "ax1.set_ylabel(\"spike rate (sp/s)\")\n",
    "ax1.set_xlabel(\"time from motion onset (ms)\")\n",
    "ax1.set_ylim(0,55)\n",
    "\n",
    "ax1.set_title(f\"Regime 3 \\n r={r}, m={m}, s={s}, X_s={x_s} beta={b}, Xr={x_r}\")\n",
    "filename = f\"results/1.2/similar_step_ramp.png\"\n",
    "ax2.set_xlabel(\"time from motion onset (ms)\")\n",
    "ax2.set_xlim(0,1000)\n",
    "fig.legend(loc=(0.55, 0.14))\n",
    "\n",
    "\n",
    "filename = f\"results/1.2/Similar models, regime 3, r={r}, m={m}, s={s}, beta={b}(regime 2).png\"\n",
    "plt.savefig(filename,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e472d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N = 4000\n",
    "T = 100\n",
    "times_ms = np.linspace(1e3/T, 1e3, T)\n",
    "beta = 1.5\n",
    "m = 0.8/beta * 100\n",
    "\n",
    "# Define the distributions\n",
    "def distribution_1(sigma):\n",
    "    return norm.pdf(times_ms/10, m, m**0.5) * 200 * N / T\n",
    "\n",
    "def distribution_2(sigma):\n",
    "    dist = norm.pdf((0.8-beta*(times_ms/1000)), 0, sigma * (times_ms/1000)**0.5)\n",
    "    return dist / np.sum(dist) * 200 * N / T\n",
    "\n",
    "# Calculate variances\n",
    "sigmas = np.linspace(0.1, 0.5, 100)\n",
    "variances_1 = [np.var(distribution_1(sigma)) for sigma in sigmas]\n",
    "variances_2 = [np.var(distribution_2(sigma)) for sigma in sigmas]\n",
    "\n",
    "# Plot the variances\n",
    "plt.plot(sigmas, variances_1, label='Distribution 1')\n",
    "plt.plot(sigmas, variances_2, label='Distribution 2')\n",
    "plt.xlabel('Sigma')\n",
    "plt.ylabel('Variance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb66917-0d16-4cb3-8946-63243c4918aa",
   "metadata": {},
   "source": [
    "### Task 1.3\n",
    "\n",
    "The PSTH is an example of a so-called first-order statistic, in that it is the averge of spike counts, $n_t$, which is their first moment. <br>\n",
    "You can also evaluate higher order statistics, such as the variance of $n_t$ (across trials).<br>\n",
    "Instead of smoothing, for evaluating the variance use larger time bins (e.g. 50 or 100 milliseconds).\n",
    "\n",
    "**How does the variance behave as a function of time and of various parameters in each model?**\n",
    "\n",
    "A more useful quantity is the Fano factor which is the ratio of the variance of $n_t$ to its mean (obviously both evaluated in the same time bin, in particular<br>\n",
    "time bins of the same width). This quantity is 1 for the Poisson distribution (the default choice for the emission distribution of both models).<br>\n",
    "**Evalute and plot the Fano Factor as a function of time, and again investigate how it changes in different parameter regimes, and importantly<br>\n",
    "whether and how it behaves differently in the two models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00151411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "T = 1000\n",
    "N = 10000\n",
    "b = 2\n",
    "s = 10\n",
    "m = 30\n",
    "r = 1200\n",
    "ramp = RampModel(beta=b, sigma=s, x0=.2, Rh=50)\n",
    "step = StepModel(m=m, r=r, x0=0.2, Rh=50)\n",
    "\n",
    "\n",
    "arr = ramp.simulate(Ntrials=N, get_rate=False, T = T)\n",
    "\n",
    "bin_size=10\n",
    "bin_edges = np.arange(0, 1e3+bin_size, bin_size)\n",
    "bin_size_2=100\n",
    "bin_edges_2 = np.arange(0, 1e3+bin_size_2, bin_size_2)   \n",
    "\n",
    "averaged_psth, gaussian_smoothed_psth, var, fano = generate_psth(spike_trains=arr[0], bin_size=bin_size, bin_size_2=bin_size_2, plot=False);\n",
    "#plt.plot(bin_edges[:-1], gaussian_smoothed_psth, linewidth=2)\n",
    "#plt.plot(bin_edges_2[:-1], var*20, linewidth=2)\n",
    "plt.plot(bin_edges_2[:-1], fano-1, linewidth=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce7738",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_list = [0.1, 0.5, 1]\n",
    "sigma_list = [0.02, 0.2, 2]\n",
    "\n",
    "for b in beta_list:\n",
    "    for s in sigma_list:\n",
    "        \n",
    "        plt.title(f\"Variance for RAMP model, sigma={s}, beta={b}, bin size = 20\")\n",
    "\n",
    "        ramp = RampModel(beta=b, sigma=s, x0=.2, Rh=50)\n",
    "        T = 100\n",
    "        N = 400\n",
    "        arr = ramp.simulate(Ntrials=N, get_rate=False, T = T)\n",
    "\n",
    "        bin_size=20\n",
    "        bin_edges = np.arange(0, 1e3+bin_size, bin_size)\n",
    "        bin_size_2=50\n",
    "        bin_edges_2 = np.arange(0, 1e3+bin_size_2, bin_size_2)   \n",
    "\n",
    "        averaged_psth, gaussian_smoothed_psth, var, fano = generate_psth(spike_trains=arr[0], bin_size=bin_size, bin_size_2=50, plot=False);\n",
    "\n",
    "        plt.plot(bin_edges_2[:-1], var, linewidth=2)\n",
    "\n",
    "        plt.ylabel(\"Variance\")\n",
    "        plt.xlabel(\"time from motion onset (ms)\")\n",
    "        plt.ylim(0,8)\n",
    "        plt.xlim(0,1000)\n",
    "\n",
    "\n",
    "        filename = f\"results/1.3/var_RAMP_s{s}_beta{b}.png\"\n",
    "        #plt.savefig(filename,bbox_inches='tight')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "#         plt.plot(bin_edges_2[:-1], fano, linewidth=2)\n",
    "#         plt.ylable(\"Fano factor\")\n",
    "#         plt.xlable(\"time from motion onset (ms)\")\n",
    "#         plt.ylim(0.8,2)\n",
    "#         plt.xlim(0,1000)\n",
    "#         filename = f\"results/1.3/fano_RAMP_s{s}_beta{b}.png\"\n",
    "#         #plt.savefig(filename,bbox_inches='tight')\n",
    "\n",
    "#         plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa91f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_list = [10,50,90]\n",
    "r_list = [1,10,100]\n",
    "for m in m_list:\n",
    "    for r in r_list:\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2)    \n",
    "        fig.suptitle(f\"PSTH for STEP model, m={m}, r={r}, bin size = 20\")\n",
    "        step = StepModel(m=m, r=r, x0=0.2, Rh=50)\n",
    "        T = 100\n",
    "        N = 400\n",
    "        arr = step.simulate(Ntrials=N, get_rate=False, T = T)\n",
    "\n",
    "        bin_size=20\n",
    "        bin_edges = np.arange(0, 1e3+bin_size, bin_size)\n",
    "        bin_size_2=50\n",
    "        bin_edges_2 = np.arange(0, 1e3+bin_size_2, bin_size_2)   \n",
    "\n",
    "        averaged_psth, gaussian_smoothed_psth, var, fano = generate_psth(spike_trains=arr[0], bin_size=bin_size, bin_size_2=50, plot=False);\n",
    "\n",
    "        ax1.plot(bin_edges_2[:-1], var, linewidth=2)\n",
    "        ax2.plot(bin_edges_2[:-1], fano, linewidth=2)\n",
    "\n",
    "        ax1.set_ylim(0,8)\n",
    "        ax1.set_xlim(0,1000)\n",
    "        ax2.set_ylim(0.8,2)\n",
    "        ax2.set_xlim(0,1000)\n",
    "\n",
    "        ax1.set_ylabel(\"Variance\")\n",
    "        ax2.set_ylabel(\"Fano factor\")\n",
    "        ax2.set_xlabel(\"time from motion onset (ms)\")\n",
    "        #filename = f\"results/1.3/var_fano_STEP_m{m}_r{r}.png\"\n",
    "        #plt.savefig(filename,bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf1821f-ef7e-436e-a443-18e45c38883f",
   "metadata": {},
   "source": [
    "### Task 1.4\n",
    "\n",
    "(This is a more open-opended and less guided task compared to the previous ones. Use brainstorming in the group and come up with creative ideas to address this, working together.)\n",
    "\n",
    "In this task you will explore an informal or relatively ad-hoc version of what we intend to do eventually using the systematic approach of Bayesian inference. <br>\n",
    "The aim is to find an intelligent but ad-hoc (in the sense that it is not Bayesian or does not rely on the models' likelihood function and only relies on \n",
    "observed statistics) way of telling the two models aparts, i.e. deciding which model generated a dataset.\n",
    "\n",
    "Relying on 1st and 2nd order statistics you have explored, or other 2nd order statistics, and perhaps higher order statistics you can come up it,\n",
    "constructing a criterion (or alternative criteria which you would compare) for deciding between the two models. To make this more challening, \n",
    "you will obviously need to put the two sets of model parameter in a regime in which they are least distinguishable from their generated spike trains. \n",
    "Use a number of trials not more than 400 for each dataset you will run your test/criterion on.\n",
    "\n",
    "You have to test your criterion by running it on several datasets, once generated by the ramp model, and in another round, generted by the step model. \n",
    "And then quantify what percent of datasets in each case where decided/classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822057de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from models2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117ce0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussion:\n",
    "# 1. How to build the classifiers, technics, threshold selection\n",
    "# 2. How to build the tester\n",
    "# 3. result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance classifier, T=100\n",
    "accuracies = classifier_tester(M=50, N=400, T=100, classifier=\"var\", thresholds=0.4);\n",
    "\n",
    "print(\"Step model accuracy: \", accuracies[0])\n",
    "print(\"Ramp model accuracy: \", accuracies[1])\n",
    "print(\"Overall accuracy: \", np.sum(accuracies)/18)\n",
    "\n",
    "\n",
    "# 1. increase T will significant increase the accuracy (Why), but T=10000 decrease even more significantly\n",
    "# 2. Redo the parameter regions, make the regions representitive (e.g. one region may represent indistinguishable part\n",
    "# some other region is the easy to distinguish part)\n",
    "# 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1ccd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance classifier, T=1000\n",
    "accuracies = classifier_tester(M=25, N=400, T=10000, classifier=\"var\", thresholds=1);\n",
    "\n",
    "print(\"Step model accuracy: \", accuracies[0])\n",
    "print(\"Ramp model accuracy: \", accuracies[1])\n",
    "print(\"Overall accuracy: \", np.sum(accuracies)/18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad Classifier \n",
    "\n",
    "def grad_classifier(spike_trains, Thresh):\n",
    "    max_grad = maximum_grad(spike_trains)\n",
    "    if max_grad>Thresh:\n",
    "        return 0 # Step model\n",
    "    else:\n",
    "        return 1 # Ramp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = generate_spike_trains(mmin=25, mmax =75, rmin=1,rmax=10, smin=0.1,smax = 0.3, bmin=0.1, bmax = 1)\n",
    "p, v, f = var_classifier(test_dataset, 1)\n",
    "plt.plot(f[0])\n",
    "plt.plot(f[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14754544",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = generate_spike_trains(M=20, N=400, T=100, m=50, r=5, sigma=0.4, beta=1)\n",
    "generate_psth(data_points[0,0], 20, 10, True);\n",
    "\n",
    "predictions = np.empty((data_points.shape[0], data_points.shape[1])) # 2 x M\n",
    "var_s = np.empty((data_points.shape[0], data_points.shape[1])) # 2 x M\n",
    "fano_factors = np.empty((data_points.shape[0], data_points.shape[1])) # 2 x M\n",
    "\n",
    "N = len(data_points[0,0,:,0])\n",
    "M=20\n",
    "grads = np.zeros((2,M,4))\n",
    "\n",
    "for ii in [0,1]:\n",
    "    # ii = 0 -> STEP spike trains\n",
    "    # ii = 1 -> RAMP spike trains\n",
    "    for jj in range(data_points[ii].shape[0]): \n",
    "        spike_trains = data_points[ii, jj]; # (N by T) spike train matrix\n",
    "        # Calculate the PSTH\n",
    "        _,psth,_,_ = generate_psth(spike_trains, bin_size=20, bin_size_2=50)\n",
    "\n",
    "\n",
    "        ### find the valid region\n",
    "        derivative = np.gradient(psth, 1/50)\n",
    "\n",
    "        # Find where the derivative is small\n",
    "        small_derivative = np.abs(derivative) < 10\n",
    "\n",
    "        # Remove these regions from the data\n",
    "        filtered_psth = psth[~small_derivative]\n",
    "\n",
    "        ### Gradient and average gradient\n",
    "\n",
    "        # Find the gradient of the PSTH\n",
    "        quat = int(len(filtered_psth)/4)\n",
    "        grad_psth_1 = np.average(np.gradient(filtered_psth[0: quat], 1/50))\n",
    "        grad_psth_2 = np.average(np.gradient(filtered_psth[quat:2*quat], 1/50))\n",
    "        grad_psth_3 = np.average(np.gradient(filtered_psth[2*quat:3*quat], 1/50))\n",
    "        grad_psth_4 = np.average(np.gradient(filtered_psth[3*quat:quat*4], 1/50))\n",
    "        average_grad = (psth[-1] - psth[1]) / len(psth)\n",
    "        \n",
    "        grads[ii,jj] = [grad_psth_1,grad_psth_2,grad_psth_3,grad_psth_4]\n",
    "        \n",
    "#         # Find the variance and the Fano factor of the gradient\n",
    "#         var = np.var(grad_psth/average_grad) / N\n",
    "#         fano_factor = var / np.mean(grad_psth/average_grad) / N\n",
    "\n",
    "#         # Print the variance and the Fano factor\n",
    "#         # print(f\"variance = {var}, Fano factor = {fano_factor}\")\n",
    "#         var_s[ii,jj] = var\n",
    "#         fano_factors[ii,jj] = fano_factor\n",
    "# print(var_s)\n",
    "\n",
    "plt.plot(grads[0,:,0], label=\"ave grad - 1st quater\")\n",
    "plt.plot(grads[0,:,1], label=\"ave grad - 2nd quater\")\n",
    "plt.plot(grads[0,:,2], label=\"ave grad - 3rd quater\")\n",
    "plt.plot(grads[0,:,3], label=\"ave grad - 4th quater\")\n",
    "plt.title(\"Four gradient, step\")\n",
    "# plt.plot(var_s[0], label = \"step\")\n",
    "# plt.plot(var_s[1], label = \"ramp\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(grads[1,:,0], label=\"ave grad - 1st quater\")\n",
    "plt.plot(grads[1,:,1], label=\"ave grad - 2nd quater\")\n",
    "plt.plot(grads[1,:,2], label=\"ave grad - 3rd quater\")\n",
    "plt.plot(grads[1,:,3], label=\"ave grad - 4th quater\")\n",
    "plt.title(\"Four gradient, ramp\")\n",
    "# plt.plot(var_s[0], label = \"step\")\n",
    "# plt.plot(var_s[1], label=\"ramp\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
